{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06e7152b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#Importing selenium webdriver\n",
    "from selenium import webdriver\n",
    "\n",
    "#Importing required Exceptions which need to be handled\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "\n",
    "#Importing requests\n",
    "import requests\n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "#Importing warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226f4427",
   "metadata": {},
   "source": [
    "#Q1. Scrape the details of most viewed videos on YouTube from Wikipedia. Url = \n",
    "https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos You need to find following details: \n",
    "A) Rank \n",
    "B) Name \n",
    "C) Artist \n",
    "D) Upload date \n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d5bb074",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Edge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "909d612e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the required page on automated browser.\n",
    "driver.get('https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bcbd12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty lists\n",
    "rank=[]\n",
    "name=[]\n",
    "artist=[]\n",
    "upload_dt=[]\n",
    "views=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44ea7f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A)scraping ranks \n",
    "rnk=driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[1]')\n",
    "for i in rnk[0:30]:\n",
    "    rank.append(i.text)\n",
    "\n",
    "#B)scraping names\n",
    "nam=driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[2]')\n",
    "for i in nam[0:30]:\n",
    "    name.append(i.text)\n",
    "    \n",
    "#C)scraping artists \n",
    "art=driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[3]')\n",
    "for i in art[0:30]:\n",
    "    artist.append(i.text)\n",
    "    \n",
    "#D)scraping upload date \n",
    "dt=driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[5]')\n",
    "for i in dt[0:30]:\n",
    "    upload_dt.append(i.text)\n",
    "    \n",
    "#E)scraping views \n",
    "view=driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[4]')\n",
    "for i in view[0:30]:\n",
    "    views.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0f78597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 30 30 30 30\n"
     ]
    }
   ],
   "source": [
    "print(len(rank),len(name),len(artist),len(upload_dt),len(views))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8406a7bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload_Date</th>\n",
       "      <th>Views(Billions)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[6]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>13.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"[9]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>8.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[16]</td>\n",
       "      <td>LooLoo Kids - Nursery Rhymes and Children's Songs</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>6.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Bath Song\"[17]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>6.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"Shape of You\"[18]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>6.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"See You Again\"[21]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>6.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Wheels on the Bus\"[26]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>5.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Phonics Song with Two Words\"[27]</td>\n",
       "      <td>ChuChu TV Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>5.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Uptown Funk\"[28]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>5.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[29]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>4.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Gangnam Style\"[30]</td>\n",
       "      <td>officialpsy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>4.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[35]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Dame Tu Cosita\"[36]</td>\n",
       "      <td>Ultra Records</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>4.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Axel F\"[37]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>4.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Sugar\"[38]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Counting Stars\"[39]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Roar\"[40]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Baa Baa Black Sheep\"[41]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td>3.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[42]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>3.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Sorry\"[43]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Lakdi Ki Kathi\"[44]</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>June 14, 2018</td>\n",
       "      <td>3.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Thinking Out Loud\"[45]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Dark Horse\"[46]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"[47]</td>\n",
       "      <td>Kiddiestv Hindi - Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>January 26, 2018</td>\n",
       "      <td>3.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Perfect\"[48]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>3.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Faded\"[49]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Let Her Go\"[50]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Girls Like You\"[51]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Lean On\"[52]</td>\n",
       "      <td>Major Lazer Official</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Bailando\"[53]</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>April 11, 2014</td>\n",
       "      <td>3.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                             Name  \\\n",
       "0    1.                            \"Baby Shark Dance\"[6]   \n",
       "1    2.                                   \"Despacito\"[9]   \n",
       "2    3.                       \"Johny Johny Yes Papa\"[16]   \n",
       "3    4.                                  \"Bath Song\"[17]   \n",
       "4    5.                               \"Shape of You\"[18]   \n",
       "5    6.                              \"See You Again\"[21]   \n",
       "6    7.                          \"Wheels on the Bus\"[26]   \n",
       "7    8.                \"Phonics Song with Two Words\"[27]   \n",
       "8    9.                                \"Uptown Funk\"[28]   \n",
       "9   10.  \"Learning Colors – Colorful Eggs on a Farm\"[29]   \n",
       "10  11.                              \"Gangnam Style\"[30]   \n",
       "11  12.   \"Masha and the Bear – Recipe for Disaster\"[35]   \n",
       "12  13.                             \"Dame Tu Cosita\"[36]   \n",
       "13  14.                                     \"Axel F\"[37]   \n",
       "14  15.                                      \"Sugar\"[38]   \n",
       "15  16.                             \"Counting Stars\"[39]   \n",
       "16  17.                                       \"Roar\"[40]   \n",
       "17  18.                        \"Baa Baa Black Sheep\"[41]   \n",
       "18  19.           \"Waka Waka (This Time for Africa)\"[42]   \n",
       "19  20.                                      \"Sorry\"[43]   \n",
       "20  21.                             \"Lakdi Ki Kathi\"[44]   \n",
       "21  22.                          \"Thinking Out Loud\"[45]   \n",
       "22  23.                                 \"Dark Horse\"[46]   \n",
       "23  24.          \"Humpty the train on a fruits ride\"[47]   \n",
       "24  25.                                    \"Perfect\"[48]   \n",
       "25  26.                                      \"Faded\"[49]   \n",
       "26  27.                                 \"Let Her Go\"[50]   \n",
       "27  28.                             \"Girls Like You\"[51]   \n",
       "28  29.                                    \"Lean On\"[52]   \n",
       "29  30.                                   \"Bailando\"[53]   \n",
       "\n",
       "                                               Artist        Upload_Date  \\\n",
       "0         Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016   \n",
       "1                                          Luis Fonsi   January 12, 2017   \n",
       "2   LooLoo Kids - Nursery Rhymes and Children's Songs    October 8, 2016   \n",
       "3                          Cocomelon - Nursery Rhymes        May 2, 2018   \n",
       "4                                          Ed Sheeran   January 30, 2017   \n",
       "5                                         Wiz Khalifa      April 6, 2015   \n",
       "6                          Cocomelon - Nursery Rhymes       May 24, 2018   \n",
       "7               ChuChu TV Nursery Rhymes & Kids Songs      March 6, 2014   \n",
       "8                                         Mark Ronson  November 19, 2014   \n",
       "9                                         Miroshka TV  February 27, 2018   \n",
       "10                                        officialpsy      July 15, 2012   \n",
       "11                                         Get Movies   January 31, 2012   \n",
       "12                                      Ultra Records      April 5, 2018   \n",
       "13                                         Crazy Frog      June 16, 2009   \n",
       "14                                           Maroon 5   January 14, 2015   \n",
       "15                                        OneRepublic       May 31, 2013   \n",
       "16                                         Katy Perry  September 5, 2013   \n",
       "17                         Cocomelon - Nursery Rhymes      June 25, 2018   \n",
       "18                                            Shakira       June 4, 2010   \n",
       "19                                      Justin Bieber   October 22, 2015   \n",
       "20                                       Jingle Toons      June 14, 2018   \n",
       "21                                         Ed Sheeran    October 7, 2014   \n",
       "22                                         Katy Perry  February 20, 2014   \n",
       "23      Kiddiestv Hindi - Nursery Rhymes & Kids Songs   January 26, 2018   \n",
       "24                                         Ed Sheeran   November 9, 2017   \n",
       "25                                        Alan Walker   December 3, 2015   \n",
       "26                                          Passenger      July 25, 2012   \n",
       "27                                           Maroon 5       May 31, 2018   \n",
       "28                               Major Lazer Official     March 22, 2015   \n",
       "29                                   Enrique Iglesias     April 11, 2014   \n",
       "\n",
       "   Views(Billions)  \n",
       "0            13.29  \n",
       "1             8.25  \n",
       "2             6.78  \n",
       "3             6.38  \n",
       "4             6.07  \n",
       "5             6.01  \n",
       "6             5.53  \n",
       "7             5.47  \n",
       "8             5.02  \n",
       "9             4.96  \n",
       "10            4.88  \n",
       "11            4.56  \n",
       "12            4.43  \n",
       "13            4.04  \n",
       "14            3.93  \n",
       "15            3.86  \n",
       "16            3.86  \n",
       "17            3.76  \n",
       "18            3.71  \n",
       "19            3.70  \n",
       "20            3.67  \n",
       "21            3.65  \n",
       "22            3.58  \n",
       "23            3.54  \n",
       "24            3.53  \n",
       "25            3.51  \n",
       "26            3.50  \n",
       "27            3.47  \n",
       "28            3.45  \n",
       "29            3.45  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe\n",
    "df1=pd.DataFrame({'Rank':rank,'Name':name,'Artist':artist,'Upload_Date':upload_dt,'Views(Billions)':views})\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fc269f",
   "metadata": {},
   "source": [
    "#Q2. Scrape the details team India’s international fixtures from bcci.tv. \n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Match title (I.e. 1 ODI) \n",
    "B) Series \n",
    "C) Place \n",
    "D) Date \n",
    "E) Time \n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d85d3b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Edge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0dae6b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the required page on automated browser.\n",
    "driver.get('https://www.bcci.tv/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85ddd154",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on menu\n",
    "menu=driver.find_element(By.XPATH,\"/html/body/nav/div[1]/button\")\n",
    "menu.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce032a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on international fixture\n",
    "international=driver.find_element(By.XPATH,\"/html/body/nav/div[1]/div[2]/ul[1]/li[2]/a\")\n",
    "international.click() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3531f55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty lists\n",
    "title_match=[]\n",
    "series=[]\n",
    "place=[]\n",
    "date=[]\n",
    "time=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5675dd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A)scraping match title \n",
    "title=driver.find_elements(By.XPATH,'//span[@class=\"matchOrderText ng-binding ng-scope\"]')\n",
    "for i in title:\n",
    "    title_match.append(i.text.replace(\"-\",\"\"))\n",
    "    \n",
    "#B)scraping series\n",
    "ser_tag=driver.find_elements(By.XPATH,'//h5[@class=\"match-tournament-name ng-binding\"]')\n",
    "for i in ser_tag:\n",
    "    series.append(i.text)\n",
    "    \n",
    "#D)scraping date\n",
    "date_tag=driver.find_elements(By.XPATH,'//div[@class=\"match-dates ng-binding\"]')\n",
    "for i in date_tag:\n",
    "    date.append(i.text)\n",
    "    \n",
    "#E)scraping time\n",
    "time_tag=driver.find_elements(By.XPATH,'//div[@class=\"match-time no-margin ng-binding\"]')\n",
    "for i in time_tag:\n",
    "    time.append(i.text)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88b3b1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 8 8 8\n"
     ]
    }
   ],
   "source": [
    "print(len(title_match),len(series),len(date),len(time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9c75a4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping stadium in place\n",
    "stadium=[]\n",
    "stdm_tag=driver.find_elements(By.XPATH,'//span[@class=\"ng-binding ng-scope\"]')\n",
    "for i in stdm_tag:\n",
    "    stadium.append(i.text)\n",
    "    \n",
    "#scraping city in place\n",
    "city=[]\n",
    "city_tag=driver.find_elements(By.XPATH,'//span[@class=\"ng-binding\"]')\n",
    "for i in city_tag:\n",
    "    city.append(i.text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "89c5bb35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 8\n"
     ]
    }
   ],
   "source": [
    "print(len(stadium),len(city))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5cfe1868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match_Title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Place_stadium</th>\n",
       "      <th>Place_city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5th ODI</td>\n",
       "      <td>ASIA CUP 2023</td>\n",
       "      <td>15 SEP 2023</td>\n",
       "      <td>3:00 PM IST</td>\n",
       "      <td>R Premadasa International Stadium,</td>\n",
       "      <td>Colombo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Final</td>\n",
       "      <td>ASIA CUP 2023</td>\n",
       "      <td>17 SEP 2023</td>\n",
       "      <td>3:00 PM IST</td>\n",
       "      <td>R Premadasa International Stadium,</td>\n",
       "      <td>Colombo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1st T20I</td>\n",
       "      <td>19TH ASIAN GAMES 2023</td>\n",
       "      <td>21 SEP 2023</td>\n",
       "      <td>6:30 AM IST</td>\n",
       "      <td>Pingfeng Cricket Field,</td>\n",
       "      <td>Hangzhou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1st ODI</td>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023-24</td>\n",
       "      <td>22 SEP 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "      <td>Punjab Cricket Association IS Bindra Stadium,</td>\n",
       "      <td>Mohali</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2nd ODI</td>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023-24</td>\n",
       "      <td>24 SEP 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "      <td>Holkar Cricket Stadium,</td>\n",
       "      <td>Indore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3rd ODI</td>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023-24</td>\n",
       "      <td>27 SEP 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "      <td>Saurashtra Cricket Association Stadium,</td>\n",
       "      <td>Rajkot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1st ODI</td>\n",
       "      <td>ICC MENS WORLD CUP 2023 WARM-UP MATCHES</td>\n",
       "      <td>30 SEP 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "      <td>Barsapara Cricket Stadium,</td>\n",
       "      <td>Guwahati</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1st T20I</td>\n",
       "      <td>19TH ASIAN GAMES 2023</td>\n",
       "      <td>3 OCT 2023</td>\n",
       "      <td>6:30 AM IST</td>\n",
       "      <td>Pingfeng Cricket Field,</td>\n",
       "      <td>Hangzhou</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Match_Title                                   Series         Date  \\\n",
       "0    5th ODI                             ASIA CUP 2023  15 SEP 2023   \n",
       "1      Final                             ASIA CUP 2023  17 SEP 2023   \n",
       "2   1st T20I                     19TH ASIAN GAMES 2023  21 SEP 2023   \n",
       "3    1st ODI           AUSTRALIA TOUR OF INDIA 2023-24  22 SEP 2023   \n",
       "4    2nd ODI           AUSTRALIA TOUR OF INDIA 2023-24  24 SEP 2023   \n",
       "5    3rd ODI           AUSTRALIA TOUR OF INDIA 2023-24  27 SEP 2023   \n",
       "6    1st ODI   ICC MENS WORLD CUP 2023 WARM-UP MATCHES  30 SEP 2023   \n",
       "7   1st T20I                     19TH ASIAN GAMES 2023   3 OCT 2023   \n",
       "\n",
       "          Time                                  Place_stadium Place_city  \n",
       "0  3:00 PM IST             R Premadasa International Stadium,    Colombo  \n",
       "1  3:00 PM IST             R Premadasa International Stadium,    Colombo  \n",
       "2  6:30 AM IST                        Pingfeng Cricket Field,   Hangzhou  \n",
       "3  1:30 PM IST  Punjab Cricket Association IS Bindra Stadium,     Mohali  \n",
       "4  1:30 PM IST                        Holkar Cricket Stadium,     Indore  \n",
       "5  1:30 PM IST        Saurashtra Cricket Association Stadium,     Rajkot  \n",
       "6  2:00 PM IST                     Barsapara Cricket Stadium,   Guwahati  \n",
       "7  6:30 AM IST                        Pingfeng Cricket Field,   Hangzhou  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe\n",
    "df2=pd.DataFrame({'Match_Title':title_match,'Series':series,'Date':date,'Time':time,'Place_stadium':stadium,'Place_city':city})\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d050fc7",
   "metadata": {},
   "source": [
    "#Q3. Scrape the details of State-wise GDP of India from statisticstime.com. \n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details:\n",
    "A)Rank \n",
    "B) State \n",
    "C) GSDP(18-19)- at current prices \n",
    "D) GSDP(19-20)- at current prices \n",
    "E) Share(18-19) \n",
    "F) GDP($ billion) \n",
    "Note: - From statisticstimes home page you have to reach to economy page through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85ba99bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Edge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ede5c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the required page on automated browser.\n",
    "driver.get('http://statisticstimes.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6691b1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on economy\n",
    "economy=driver.find_element(By.XPATH,\"/html/body/div[2]/div[1]/div[2]/div[2]/button\")\n",
    "economy.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c7871af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on india in economy\n",
    "ind_economy=driver.find_element(By.XPATH,'/html/body/div[2]/div[1]/div[2]/div[2]/div/a[3]')\n",
    "ind_economy.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e06d9b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on GDP of Indian states\n",
    "state_gdp=driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div[2]/ul/li[1]/a')\n",
    "state_gdp.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36704b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty lists\n",
    "rank=[]\n",
    "state=[]\n",
    "gsdp_1819=[]\n",
    "gsdp_1920=[]\n",
    "share=[]\n",
    "gdp=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9671eb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A)scraping rank \n",
    "try:\n",
    "    rnk=driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"]/tbody/tr/td[1]')\n",
    "    for i in rnk[0:33]:\n",
    "        rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    rank.append('-')\n",
    "\n",
    "#B)scraping state\n",
    "try:\n",
    "    stat=driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"]/tbody/tr/td[2]')\n",
    "    for i in stat[0:33]:\n",
    "        state.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    state.append('-')\n",
    "    \n",
    "#C)scraping GSDP(18-19)- at current prices \n",
    "try:\n",
    "    gsdp1=driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"]/tbody/tr/td[4]')\n",
    "    for i in gsdp1[0:33]:\n",
    "        gsdp_1819.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    gsdp_1819.append('-')\n",
    "    \n",
    "#D)scraping GSDP(19-20)- at current prices \n",
    "try:\n",
    "    gsdp2=driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"]/tbody/tr/td[3]')\n",
    "    for i in gsdp2[0:33]:\n",
    "        gsdp_1920.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    gsdp_1920.append('-')\n",
    "    \n",
    "#E)scraping Share(18-19) \n",
    "try:\n",
    "    shr=driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"]/tbody/tr/td[5]')\n",
    "    for i in shr[0:33]:\n",
    "        share.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    share.append('-')\n",
    "    \n",
    "#F)scraping GDP($ billion) \n",
    "try:\n",
    "    gdp_tag=driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"]/tbody/tr/td[6]')\n",
    "    for i in gdp_tag[0:33]:\n",
    "        gdp.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    gdp.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "54a86e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 33 33 33 33 33\n"
     ]
    }
   ],
   "source": [
    "print(len(rank),len(state),len(gsdp_1819),len(gsdp_1920),len(share),len(gdp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a3bdd88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP(18-19)_@cp</th>\n",
       "      <th>GSDP(19-20)_@cp</th>\n",
       "      <th>Share(18-19)</th>\n",
       "      <th>GDP($billion)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>-</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>-</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>942,586</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>862,957</td>\n",
       "      <td>972,782</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>861,031</td>\n",
       "      <td>969,604</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>809,592</td>\n",
       "      <td>906,672</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>781,653</td>\n",
       "      <td>-</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>774,870</td>\n",
       "      <td>856,112</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>734,163</td>\n",
       "      <td>831,610</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>530,363</td>\n",
       "      <td>611,804</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>526,376</td>\n",
       "      <td>574,760</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>487,805</td>\n",
       "      <td>521,275</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>315,881</td>\n",
       "      <td>-</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>304,063</td>\n",
       "      <td>329,180</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>297,204</td>\n",
       "      <td>328,598</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>245,895</td>\n",
       "      <td>-</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>155,956</td>\n",
       "      <td>-</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>153,845</td>\n",
       "      <td>165,472</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>73,170</td>\n",
       "      <td>80,449</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>49,845</td>\n",
       "      <td>55,984</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>42,114</td>\n",
       "      <td>-</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>34,433</td>\n",
       "      <td>38,253</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>33,481</td>\n",
       "      <td>36,572</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>28,723</td>\n",
       "      <td>32,496</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>27,870</td>\n",
       "      <td>31,790</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>27,283</td>\n",
       "      <td>-</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>24,603</td>\n",
       "      <td>-</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>22,287</td>\n",
       "      <td>26,503</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State GSDP(18-19)_@cp GSDP(19-20)_@cp  \\\n",
       "0     1                Maharashtra       2,632,792               -   \n",
       "1     2                 Tamil Nadu       1,630,208       1,845,853   \n",
       "2     3              Uttar Pradesh       1,584,764       1,687,818   \n",
       "3     4                    Gujarat       1,502,899               -   \n",
       "4     5                  Karnataka       1,493,127       1,631,977   \n",
       "5     6                West Bengal       1,089,898       1,253,832   \n",
       "6     7                  Rajasthan         942,586       1,020,989   \n",
       "7     8             Andhra Pradesh         862,957         972,782   \n",
       "8     9                  Telangana         861,031         969,604   \n",
       "9    10             Madhya Pradesh         809,592         906,672   \n",
       "10   11                     Kerala         781,653               -   \n",
       "11   12                      Delhi         774,870         856,112   \n",
       "12   13                    Haryana         734,163         831,610   \n",
       "13   14                      Bihar         530,363         611,804   \n",
       "14   15                     Punjab         526,376         574,760   \n",
       "15   16                     Odisha         487,805         521,275   \n",
       "16   17                      Assam         315,881               -   \n",
       "17   18               Chhattisgarh         304,063         329,180   \n",
       "18   19                  Jharkhand         297,204         328,598   \n",
       "19   20                Uttarakhand         245,895               -   \n",
       "20   21            Jammu & Kashmir         155,956               -   \n",
       "21   22           Himachal Pradesh         153,845         165,472   \n",
       "22   23                        Goa          73,170          80,449   \n",
       "23   24                    Tripura          49,845          55,984   \n",
       "24   25                 Chandigarh          42,114               -   \n",
       "25   26                 Puducherry          34,433          38,253   \n",
       "26   27                  Meghalaya          33,481          36,572   \n",
       "27   28                     Sikkim          28,723          32,496   \n",
       "28   29                    Manipur          27,870          31,790   \n",
       "29   30                   Nagaland          27,283               -   \n",
       "30   31          Arunachal Pradesh          24,603               -   \n",
       "31   32                    Mizoram          22,287          26,503   \n",
       "32   33  Andaman & Nicobar Islands               -               -   \n",
       "\n",
       "   Share(18-19) GDP($billion)  \n",
       "0        13.94%       399.921  \n",
       "1         8.63%       247.629  \n",
       "2         8.39%       240.726  \n",
       "3         7.96%       228.290  \n",
       "4         7.91%       226.806  \n",
       "5         5.77%       165.556  \n",
       "6         4.99%       143.179  \n",
       "7         4.57%       131.083  \n",
       "8         4.56%       130.791  \n",
       "9         4.29%       122.977  \n",
       "10        4.14%       118.733  \n",
       "11        4.10%       117.703  \n",
       "12        3.89%       111.519  \n",
       "13        2.81%        80.562  \n",
       "14        2.79%        79.957  \n",
       "15        2.58%        74.098  \n",
       "16        1.67%        47.982  \n",
       "17        1.61%        46.187  \n",
       "18        1.57%        45.145  \n",
       "19        1.30%        37.351  \n",
       "20        0.83%        23.690  \n",
       "21        0.81%        23.369  \n",
       "22        0.39%        11.115  \n",
       "23        0.26%         7.571  \n",
       "24        0.22%         6.397  \n",
       "25        0.18%         5.230  \n",
       "26        0.18%         5.086  \n",
       "27        0.15%         4.363  \n",
       "28        0.15%         4.233  \n",
       "29        0.14%         4.144  \n",
       "30        0.13%         3.737  \n",
       "31        0.12%         3.385  \n",
       "32            -             -  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe\n",
    "df3=pd.DataFrame({'Rank':rank,'State':state,'GSDP(18-19)_@cp':gsdp_1819,'GSDP(19-20)_@cp':gsdp_1920,'Share(18-19)':share,'GDP($billion)':gdp})\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de550b99",
   "metadata": {},
   "source": [
    "#Q4. Scrape the details of trending repositories on Github.com. \n",
    "Url = https://github.com/\n",
    "You have to find the following details: \n",
    "A) Repository title \n",
    "B) Repository description \n",
    "C) Contributors count \n",
    "D) Language used \n",
    "Note: - From the home page you have to click on the trending option from Explore menu through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b6f372e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Edge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc908915",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the required page on automated browser.\n",
    "driver.get('https://github.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a96fa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on explore\n",
    "explore=driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/header/div/div[1]/div[2]/button\")\n",
    "explore.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c736c624",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on open_source\n",
    "source_clk=driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/button\")\n",
    "source_clk.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e5272ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on trending\n",
    "trending=driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/div/div[3]/ul/li[2]/a\")\n",
    "trending.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9659081a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty lists\n",
    "title=[]\n",
    "descrip=[]\n",
    "count=[]\n",
    "language=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a545e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A)scraping repository title \n",
    "try:\n",
    "    titl=driver.find_elements(By.XPATH,'//a[@class=\"Link\"]')\n",
    "    for i in titl:\n",
    "        title.append(i.text)\n",
    "except NoSuchElementException :\n",
    "    title.append('-')\n",
    "        \n",
    "#B)scraping repository description\n",
    "try:\n",
    "    desp=driver.find_elements(By.XPATH,'//p[@class=\"col-9 color-fg-muted my-1 pr-4\"]')\n",
    "    for i in desp:\n",
    "        descrip.append(i.text)\n",
    "except NoSuchElementException :\n",
    "    descrip.append('-')\n",
    "    \n",
    "#C)scraping contributors count\n",
    "try:\n",
    "    cont=driver.find_elements(By.XPATH,'//a[@class=\"Link Link--muted d-inline-block mr-3\"][2]')\n",
    "    for i in cont:\n",
    "        count.append(i.text)\n",
    "except NoSuchElementException :\n",
    "    count.append('-')\n",
    "    \n",
    "#D)scraping language used\n",
    "try:\n",
    "    lang=driver.find_elements(By.XPATH,'//span[@class=\"d-inline-block ml-0 mr-3\"]/span[2]')\n",
    "    for i in lang:\n",
    "        language.append(i.text)\n",
    "except NoSuchElementException :\n",
    "    language.append('-')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e6be34e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 24 25 23\n"
     ]
    }
   ],
   "source": [
    "print(len(title),len(descrip),len(count),len(language))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "762bbe04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository_title</th>\n",
       "      <th>Repository_description</th>\n",
       "      <th>Contributors_count</th>\n",
       "      <th>Language_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hyperdxio / hyperdx</td>\n",
       "      <td>Resolve production issues, fast. An open sourc...</td>\n",
       "      <td>88</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>williamyang1991 / Rerender_A_Video</td>\n",
       "      <td>[SIGGRAPH Asia 2023] Rerender A Video: Zero-Sh...</td>\n",
       "      <td>85</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NExT-GPT / NExT-GPT</td>\n",
       "      <td>Code and models for NExT-GPT: Any-to-Any Multi...</td>\n",
       "      <td>94</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>makeplane / plane</td>\n",
       "      <td>🔥 🔥 🔥 Open Source JIRA, Linear and Height Alte...</td>\n",
       "      <td>659</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>grafana / beyla</td>\n",
       "      <td>eBPF-based autoinstrumentation of HTTP and HTT...</td>\n",
       "      <td>28</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CorentinJ / Real-Time-Voice-Cloning</td>\n",
       "      <td>Clone a voice in 5 seconds to generate arbitra...</td>\n",
       "      <td>8,055</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mastodon / mastodon</td>\n",
       "      <td>Your self-hosted, globally interconnected micr...</td>\n",
       "      <td>6,567</td>\n",
       "      <td>Ruby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AntonioErdeljac / next13-lms-platform</td>\n",
       "      <td>Self-hosted AI coding assistant</td>\n",
       "      <td>57</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TabbyML / tabby</td>\n",
       "      <td>Deploy web apps anywhere.</td>\n",
       "      <td>340</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>basecamp / kamal</td>\n",
       "      <td>Godot Engine – Multi-platform 2D and 3D game e...</td>\n",
       "      <td>241</td>\n",
       "      <td>Ruby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>godotengine / godot</td>\n",
       "      <td>The React Framework</td>\n",
       "      <td>14,405</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>vercel / next.js</td>\n",
       "      <td>A list of SaaS, PaaS and IaaS offerings that h...</td>\n",
       "      <td>24,753</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ripienaar / free-for-dev</td>\n",
       "      <td>An Open-source Framework for Autonomous Langua...</td>\n",
       "      <td>8,106</td>\n",
       "      <td>HTML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>aiwaves-cn / agents</td>\n",
       "      <td>Data set of top third party web domains with r...</td>\n",
       "      <td>148</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>duckduckgo / tracker-radar</td>\n",
       "      <td>Elegant HTTP Networking in Swift</td>\n",
       "      <td>158</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Alamofire / Alamofire</td>\n",
       "      <td>🐸💬 - a deep learning toolkit for Text-to-Speec...</td>\n",
       "      <td>7,507</td>\n",
       "      <td>Swift</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>coqui-ai / TTS</td>\n",
       "      <td>[ICCV 2023] ProPainter: Improving Propagation ...</td>\n",
       "      <td>2,147</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>sczhou / ProPainter</td>\n",
       "      <td>Toy Gaussian Splatting visualization in Unity</td>\n",
       "      <td>69</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>aras-p / UnityGaussianSplatting</td>\n",
       "      <td>「Java学习+面试指南」一份涵盖大部分 Java 程序员所需要掌握的核心知识。准备 Jav...</td>\n",
       "      <td>26</td>\n",
       "      <td>C#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Snailclimb / JavaGuide</td>\n",
       "      <td>The paper list of the 86-page paper \"The Rise ...</td>\n",
       "      <td>44,828</td>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>WooooDyy / LLM-Agent-Paper-List</td>\n",
       "      <td>A list of awesome beginners-friendly projects.</td>\n",
       "      <td>87</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>MunGell / awesome-for-beginners</td>\n",
       "      <td>A modern formatting library</td>\n",
       "      <td>6,568</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>fmtlib / fmt</td>\n",
       "      <td>Meshery, the cloud native manager</td>\n",
       "      <td>2,164</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Repository_title  \\\n",
       "0                     hyperdxio / hyperdx   \n",
       "1      williamyang1991 / Rerender_A_Video   \n",
       "2                     NExT-GPT / NExT-GPT   \n",
       "3                       makeplane / plane   \n",
       "4                         grafana / beyla   \n",
       "5     CorentinJ / Real-Time-Voice-Cloning   \n",
       "6                     mastodon / mastodon   \n",
       "7   AntonioErdeljac / next13-lms-platform   \n",
       "8                         TabbyML / tabby   \n",
       "9                        basecamp / kamal   \n",
       "10                    godotengine / godot   \n",
       "11                       vercel / next.js   \n",
       "12               ripienaar / free-for-dev   \n",
       "13                    aiwaves-cn / agents   \n",
       "14             duckduckgo / tracker-radar   \n",
       "15                  Alamofire / Alamofire   \n",
       "16                         coqui-ai / TTS   \n",
       "17                    sczhou / ProPainter   \n",
       "18        aras-p / UnityGaussianSplatting   \n",
       "19                 Snailclimb / JavaGuide   \n",
       "20        WooooDyy / LLM-Agent-Paper-List   \n",
       "21        MunGell / awesome-for-beginners   \n",
       "22                           fmtlib / fmt   \n",
       "\n",
       "                               Repository_description Contributors_count  \\\n",
       "0   Resolve production issues, fast. An open sourc...                 88   \n",
       "1   [SIGGRAPH Asia 2023] Rerender A Video: Zero-Sh...                 85   \n",
       "2   Code and models for NExT-GPT: Any-to-Any Multi...                 94   \n",
       "3   🔥 🔥 🔥 Open Source JIRA, Linear and Height Alte...                659   \n",
       "4   eBPF-based autoinstrumentation of HTTP and HTT...                 28   \n",
       "5   Clone a voice in 5 seconds to generate arbitra...              8,055   \n",
       "6   Your self-hosted, globally interconnected micr...              6,567   \n",
       "7                     Self-hosted AI coding assistant                 57   \n",
       "8                           Deploy web apps anywhere.                340   \n",
       "9   Godot Engine – Multi-platform 2D and 3D game e...                241   \n",
       "10                                The React Framework             14,405   \n",
       "11  A list of SaaS, PaaS and IaaS offerings that h...             24,753   \n",
       "12  An Open-source Framework for Autonomous Langua...              8,106   \n",
       "13  Data set of top third party web domains with r...                148   \n",
       "14                   Elegant HTTP Networking in Swift                158   \n",
       "15  🐸💬 - a deep learning toolkit for Text-to-Speec...              7,507   \n",
       "16  [ICCV 2023] ProPainter: Improving Propagation ...              2,147   \n",
       "17      Toy Gaussian Splatting visualization in Unity                 69   \n",
       "18  「Java学习+面试指南」一份涵盖大部分 Java 程序员所需要掌握的核心知识。准备 Jav...                 26   \n",
       "19  The paper list of the 86-page paper \"The Rise ...             44,828   \n",
       "20     A list of awesome beginners-friendly projects.                 87   \n",
       "21                        A modern formatting library              6,568   \n",
       "22                  Meshery, the cloud native manager              2,164   \n",
       "\n",
       "       Language_used  \n",
       "0         TypeScript  \n",
       "1   Jupyter Notebook  \n",
       "2             Python  \n",
       "3         TypeScript  \n",
       "4                  C  \n",
       "5             Python  \n",
       "6               Ruby  \n",
       "7         TypeScript  \n",
       "8         TypeScript  \n",
       "9               Ruby  \n",
       "10               C++  \n",
       "11        JavaScript  \n",
       "12              HTML  \n",
       "13            Python  \n",
       "14        JavaScript  \n",
       "15             Swift  \n",
       "16            Python  \n",
       "17            Python  \n",
       "18                C#  \n",
       "19              Java  \n",
       "20               C++  \n",
       "21                Go  \n",
       "22            Python  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe\n",
    "df4=pd.DataFrame({'Repository_title':title[0:23],'Repository_description':descrip[0:23],'Contributors_count':count[0:23],'Language_used':language})\n",
    "df4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d154a2",
   "metadata": {},
   "source": [
    "#Q5. Scrape the details of top 100 songs on billiboard.com. Url = https:/www.billboard.com/\n",
    "You have to find the following details: \n",
    "A) Song name \n",
    "B) Artist name \n",
    "C) Last week rank \n",
    "D) Peak rank \n",
    "E) Weeks on board \n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a946ca2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Edge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54bde887",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the required page on automated browser.\n",
    "driver.get('https:/www.billboard.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff137965",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on explore\n",
    "explore2=driver.find_element(By.XPATH,\"/html/body/div[3]/header/div/div[4]/div/div[1]/div[1]/button\")\n",
    "explore2.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd6e1300",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on charts\n",
    "chart=driver.find_element(By.XPATH,\"/html/body/div[3]/div[9]/div/div/div/ul/li[1]/h3/a\")\n",
    "chart.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3601f687",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on hot 100-page\n",
    "hot_100_page=driver.find_element(By.XPATH,\"/html/body/div[3]/main/div[2]/div[1]/div[1]/div/div/div[1]/div/div[2]/span/a\")\n",
    "hot_100_page.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24ea5a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty lists\n",
    "sname=[]\n",
    "artist=[]\n",
    "rank_lw=[]\n",
    "peak_rank=[]\n",
    "weeks=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "684d7842",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A)scraping song names \n",
    "name=driver.find_elements(By.XPATH,'//div[@class=\"o-chart-results-list-row-container\"]//li/h3[1]')\n",
    "for i in name:\n",
    "    sname.append(i.text)\n",
    "\n",
    "#B)scraping artist names\n",
    "art=driver.find_elements(By.XPATH,'//div[@class=\"o-chart-results-list-row-container\"]/ul/li[4]/ul/li[1]/span')\n",
    "for i in art:\n",
    "    artist.append(i.text)\n",
    "    \n",
    "#C)scraping last week rank \n",
    "rank1=driver.find_elements(By.XPATH,'//div[@class=\"o-chart-results-list-row-container\"]/ul/li[4]/ul/li[4]/span')\n",
    "for i in rank1:\n",
    "    rank_lw.append(i.text)\n",
    "    \n",
    "#D)scraping peak rank \n",
    "rank2=driver.find_elements(By.XPATH,'//div[@class=\"o-chart-results-list-row-container\"]/ul/li[4]/ul/li[5]/span')\n",
    "for i in rank2:\n",
    "    peak_rank.append(i.text)\n",
    "    \n",
    "#E)scraping weeks \n",
    "week=driver.find_elements(By.XPATH,'//div[@class=\"o-chart-results-list-row-container\"]/ul/li[4]/ul/li[6]/span')\n",
    "for i in week:\n",
    "    weeks.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "914b4b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(sname),len(artist),len(rank_lw),len(peak_rank),len(weeks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "741da03a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song_Name</th>\n",
       "      <th>Artist_Name</th>\n",
       "      <th>LastWeek_Rank</th>\n",
       "      <th>Peak_rank</th>\n",
       "      <th>Weeks_on_Board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vampire</td>\n",
       "      <td>Olivia Rodrigo</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Paint The Town Red</td>\n",
       "      <td>Doja Cat</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I Remember Everything</td>\n",
       "      <td>Zach Bryan Featuring Kacey Musgraves</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fast Car</td>\n",
       "      <td>Luke Combs</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cruel Summer</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Lagunas</td>\n",
       "      <td>Peso Pluma &amp; Jasiel Nunez</td>\n",
       "      <td>-</td>\n",
       "      <td>77</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Sittin' On Top Of The World</td>\n",
       "      <td>Burna Boy</td>\n",
       "      <td>86</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Rubicon</td>\n",
       "      <td>Peso Pluma</td>\n",
       "      <td>95</td>\n",
       "      <td>63</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>TQM</td>\n",
       "      <td>Fuerza Regida</td>\n",
       "      <td>89</td>\n",
       "      <td>34</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Amargura</td>\n",
       "      <td>Karol G</td>\n",
       "      <td>91</td>\n",
       "      <td>85</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Song_Name                           Artist_Name  \\\n",
       "0                       Vampire                        Olivia Rodrigo   \n",
       "1            Paint The Town Red                              Doja Cat   \n",
       "2         I Remember Everything  Zach Bryan Featuring Kacey Musgraves   \n",
       "3                      Fast Car                            Luke Combs   \n",
       "4                  Cruel Summer                          Taylor Swift   \n",
       "..                          ...                                   ...   \n",
       "95                      Lagunas             Peso Pluma & Jasiel Nunez   \n",
       "96  Sittin' On Top Of The World                             Burna Boy   \n",
       "97                      Rubicon                            Peso Pluma   \n",
       "98                          TQM                         Fuerza Regida   \n",
       "99                     Amargura                               Karol G   \n",
       "\n",
       "   LastWeek_Rank Peak_rank Weeks_on_Board  \n",
       "0              9         1             11  \n",
       "1              1         1              6  \n",
       "2              2         1              3  \n",
       "3              3         2             25  \n",
       "4              4         3             19  \n",
       "..           ...       ...            ...  \n",
       "95             -        77              9  \n",
       "96            86        80              3  \n",
       "97            95        63             11  \n",
       "98            89        34             17  \n",
       "99            91        85              5  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe\n",
    "df5=pd.DataFrame({'Song_Name':sname,'Artist_Name':artist,'LastWeek_Rank':rank_lw,'Peak_rank':peak_rank,'Weeks_on_Board':weeks})\n",
    "df5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ba8cbd",
   "metadata": {},
   "source": [
    "#Q6. Scrape the details of Highest selling novels. \n",
    "URL= https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\n",
    "You have to find the following details:\n",
    "A) Book name \n",
    "B) Author name \n",
    "C) Volumes sold \n",
    "D) Publisher \n",
    "E) Genre "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6d292dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Edge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "efd0d02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the required page on automated browser.\n",
    "driver.get('https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "559d4e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty lists\n",
    "book=[]\n",
    "author=[]\n",
    "vsold=[]\n",
    "publisher=[]\n",
    "genre=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a14900db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A)scraping book names \n",
    "bnam=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[2]')\n",
    "for i in bnam:\n",
    "    book.append(i.text)\n",
    "\n",
    "#B)scraping author names\n",
    "auth=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[3]')\n",
    "for i in auth:\n",
    "    author.append(i.text)\n",
    "    \n",
    "#C)scraping volumes sold \n",
    "vol=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[4]')\n",
    "for i in vol:\n",
    "    vsold.append(i.text)\n",
    "    \n",
    "#D)scraping publisher \n",
    "publsh=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[5]')\n",
    "for i in publsh:\n",
    "    publisher.append(i.text)\n",
    "    \n",
    "#E)scraping genre \n",
    "genr=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[6]')\n",
    "for i in genr:\n",
    "    genre.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c21bb5eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(book),len(author),len(vsold),len(publisher),len(genre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07496b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book_Name</th>\n",
       "      <th>Author_Name</th>\n",
       "      <th>Volume_sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book_Name       Author_Name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volume_sold        Publisher                        Genre  \n",
       "0    5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1    4,475,152       Bloomsbury           Children's Fiction  \n",
       "2    4,200,654       Bloomsbury           Children's Fiction  \n",
       "3    4,179,479       Bloomsbury           Children's Fiction  \n",
       "4    3,758,936     Random House              Romance & Sagas  \n",
       "..         ...              ...                          ...  \n",
       "95     807,311     Random House   General & Literary Fiction  \n",
       "96     794,201          Penguin        Food & Drink: General  \n",
       "97     792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98     791,507            Orion           Biography: General  \n",
       "99     791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe\n",
    "df6=pd.DataFrame({'Book_Name':book,'Author_Name':author,'Volume_sold':vsold,'Publisher':publisher,'Genre':genre})\n",
    "df6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db70056",
   "metadata": {},
   "source": [
    "#Q7. Scrape the details most watched tv series of all time from imdb.com. \n",
    "Url = https://www.imdb.com/list/ls095964455/ You \n",
    "have to find the following details: \n",
    "A) Name \n",
    "B) Year span \n",
    "C) Genre \n",
    "D) Run time \n",
    "E) Ratings \n",
    "F) Votes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "506e20a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Edge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50443157",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the required page on automated browser.\n",
    "driver.get('https://www.imdb.com/list/ls095964455/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26898d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty lists\n",
    "name=[]\n",
    "span_yr=[]\n",
    "genre1=[]\n",
    "runtime=[]\n",
    "ratings=[]\n",
    "votes=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef0304b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A)scraping series names \n",
    "snam=driver.find_elements(By.XPATH,'//div[@class=\"lister-item-content\"]/h3/a')\n",
    "for i in snam:\n",
    "    name.append(i.text)\n",
    "\n",
    "#B)scraping year span\n",
    "year=driver.find_elements(By.XPATH,'//div[@class=\"lister-item-content\"]/h3/span[2]')\n",
    "for i in year:\n",
    "    span_yr.append(i.text)\n",
    "    \n",
    "#C)scraping genre \n",
    "gen=driver.find_elements(By.XPATH,'//div[@class=\"lister-item-content\"]/p[1]/span[5]')\n",
    "for i in gen:\n",
    "    genre1.append(i.text)\n",
    "    \n",
    "#D)scraping runtime \n",
    "rtime=driver.find_elements(By.XPATH,'//div[@class=\"lister-item-content\"]/p[1]/span[3]')\n",
    "for i in rtime:\n",
    "    runtime.append(i.text)\n",
    "    \n",
    "#E)scraping ratings \n",
    "rat=driver.find_elements(By.XPATH,'//div[@class=\"lister-item-content\"]/div[1]/div[1]/span[2]')\n",
    "for i in rat:\n",
    "    ratings.append(i.text)\n",
    "    \n",
    "#F)scraping votes \n",
    "vote=driver.find_elements(By.XPATH,'//div[@class=\"lister-item-content\"]/p[4]/span[2]')\n",
    "for i in vote:\n",
    "    votes.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "967d77b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(name),len(span_yr),len(genre1),len(runtime),len(ratings),len(votes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30ac9056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Series_Name</th>\n",
       "      <th>Span_Year</th>\n",
       "      <th>Genre</th>\n",
       "      <th>RunTime</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,205,101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016–2025)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,276,454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1,046,261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>307,502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>266,575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>52,749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>64,810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005– )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>211,109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7</td>\n",
       "      <td>43,923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>266,195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Series_Name    Span_Year                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things  (2016–2025)    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)                     Drama   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds     (2005– )     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "    RunTime Ratings      Votes  \n",
       "0    57 min     9.2  2,205,101  \n",
       "1    51 min     8.7  1,276,454  \n",
       "2    44 min     8.1  1,046,261  \n",
       "3    60 min     7.5    307,502  \n",
       "4    43 min     7.6    266,575  \n",
       "..      ...     ...        ...  \n",
       "95   42 min     7.5     52,749  \n",
       "96   50 min     7.8     64,810  \n",
       "97   42 min     8.1    211,109  \n",
       "98   45 min       7     43,923  \n",
       "99  572 min     8.6    266,195  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe\n",
    "df7=pd.DataFrame({'Series_Name':name,'Span_Year':span_yr,'Genre':genre1,'RunTime':runtime,'Ratings':ratings,'Votes':votes})\n",
    "df7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146d540d",
   "metadata": {},
   "source": [
    "#Q8.Details of Datasets from UCI machine learning repositories. \n",
    "Url = https://archive.ics.uci.edu/\n",
    "You have to find the following details: \n",
    "A) Dataset name \n",
    "B) Data type \n",
    "C) Task \n",
    "D) Attribute type \n",
    "E) No of instances \n",
    "F) No of attribute \n",
    "G) Year\n",
    "Note: - from the home page you have to go to the Show All Dataset page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "608cbfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Edge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5b93f630",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the required page on automated browser.\n",
    "driver.get('https://archive.ics.uci.edu/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6230eb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on all dataset\n",
    "dataset=driver.find_element(By.XPATH,\"/html/body/div/div[1]/div[1]/main/div/div[1]/div/div/div/a[1]\")\n",
    "dataset.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8a01c2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on expand\n",
    "expand=driver.find_element(By.XPATH,\"/html/body/div/div[1]/div[1]/main/div/div[2]/div[1]/div/label[2]/div[2]/span[2]\")\n",
    "expand.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9d274bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty lists\n",
    "dsname=[]\n",
    "dtype=[]\n",
    "task=[]\n",
    "att_type=[]\n",
    "instances=[]\n",
    "no_att=[]\n",
    "year=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8f54c6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping dataset names from pages\n",
    "start=0\n",
    "end=9\n",
    "for page in range(start,end):\n",
    "    try:\n",
    "        names=driver.find_elements(By.XPATH,'//a[@class=\"link-hover link text-xl font-semibold\"]')\n",
    "        for i in names:\n",
    "            dsname.append(i.text)\n",
    "        next_button=driver.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[2]/div[3]/div/button[2]')\n",
    "        next_button.click()\n",
    "        time.sleep(2)\n",
    "    except NoSuchElementException :\n",
    "        dsname.append('-')\n",
    "    \n",
    "#scraping datatypes from pages.\n",
    "start=0\n",
    "end=9\n",
    "for page in range(start,end):\n",
    "    try:\n",
    "        types=driver.find_elements(By.XPATH,'//div[1]/div[2]/div/div[1]/span[@class=\"truncate\"]')\n",
    "        for i in types:\n",
    "            dtype.append(i.text)\n",
    "        next_button=driver.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[2]/div[3]/div/button[2]')\n",
    "        next_button.click()\n",
    "        time.sleep(2)\n",
    "    except NoSuchElementException :\n",
    "        dtype.append('-')\n",
    "    \n",
    "#scraping task from pages.\n",
    "start=0\n",
    "end=9\n",
    "for page in range(start,end):\n",
    "    try:\n",
    "        tsk=driver.find_elements(By.XPATH,'//p[@class=\"truncate\"]')\n",
    "        for i in tsk:\n",
    "            task.append(i.text)\n",
    "        next_button=driver.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[2]/div[3]/div/button[2]')\n",
    "        next_button.click()\n",
    "        time.sleep(2)\n",
    "    except NoSuchElementException :\n",
    "        task.append('-')\n",
    "\n",
    "#scraping attribute type from pages.\n",
    "start=0\n",
    "end=9\n",
    "for page in range(start,end):\n",
    "    try:\n",
    "        att=driver.find_elements(By.XPATH,'//div[1]/div[2]/div/div[2]/span[@class=\"truncate\"]')\n",
    "        for i in att:\n",
    "            att_type.append(i.text)\n",
    "        next_button=driver.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[2]/div[3]/div/button[2]')\n",
    "        next_button.click()\n",
    "        time.sleep(2)\n",
    "    except NoSuchElementException :\n",
    "        att_type.append('-')\n",
    "    \n",
    "#scraping no. of instances from pages\n",
    "start=0\n",
    "end=9\n",
    "for page in range(start,end):\n",
    "    try:\n",
    "        inst=driver.find_elements(By.XPATH,'//div[1]/div[2]/div/div[3]/span[@class=\"truncate\"]')\n",
    "        for i in inst:\n",
    "            instances.append(i.text)\n",
    "        next_button=driver.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[2]/div[3]/div/button[2]')\n",
    "        next_button.click()\n",
    "        time.sleep(2)\n",
    "    except NoSuchElementException :\n",
    "        instances.append('-')\n",
    "    \n",
    "#scraping no. of attribute from pages\n",
    "start=0\n",
    "end=9\n",
    "for page in range(start,end):\n",
    "    try:\n",
    "        att=driver.find_elements(By.XPATH,'//div[1]/div[2]/div/div[4]/span[@class=\"truncate\"]')\n",
    "        for i in att:\n",
    "            no_att.append(i.text)\n",
    "        next_button=driver.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[2]/div[3]/div/button[2]')\n",
    "        next_button.click()\n",
    "        time.sleep(2)\n",
    "    except NoSuchElementException :\n",
    "        no_att.append('-')\n",
    "    \n",
    "#scraping year from pages\n",
    "start=0\n",
    "end=9\n",
    "for page in range(start,end):\n",
    "    try:\n",
    "        yr=driver.find_elements(By.XPATH,'//tbody[@class=\"border\"]/tr/td[3]')\n",
    "        for i in yr:\n",
    "            year.append(i.text)\n",
    "        next_button=driver.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[2]/div[3]/div/button[2]')\n",
    "        next_button.click()\n",
    "        time.sleep(2)\n",
    "    except NoSuchElementException :\n",
    "        year.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "12bb40b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 90 90 90 90 90\n"
     ]
    }
   ],
   "source": [
    "print(len(dsname),len(dtype),len(task),len(att_type),len(instances),len(no_att))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "74260b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset_Name</th>\n",
       "      <th>Data_type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute_type</th>\n",
       "      <th>No_Of_Instances</th>\n",
       "      <th>No_of_Attribute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris</td>\n",
       "      <td>Classification, Clustering</td>\n",
       "      <td>This hourly data set considers 6 main air poll...</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>399 Instances</td>\n",
       "      <td>4 Features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heart Disease</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Accelerometer and transdermal alcohol content ...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>288K Instances</td>\n",
       "      <td>49 Features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Contains weekly purchased quantities of 800 ov...</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>329 Instances</td>\n",
       "      <td>12 Features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dry Bean Dataset</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Reviews on destinations in 10 categories menti...</td>\n",
       "      <td>Multivariate, Text</td>\n",
       "      <td>24.02K Instances</td>\n",
       "      <td>2.4K Features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Diabetes</td>\n",
       "      <td>Classification, Regression, Clustering</td>\n",
       "      <td>Bilateral (left, right) joint angle (ankle, kn...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>422.94K Instances</td>\n",
       "      <td>5 Features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Musk (Version 1)</td>\n",
       "      <td></td>\n",
       "      <td>Prediction of the release year of a song from ...</td>\n",
       "      <td>Text</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Haberman's Survival</td>\n",
       "      <td>Classification</td>\n",
       "      <td>This dataset represents ambient data collected...</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>237 Instances</td>\n",
       "      <td>9 Features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Real estate valuation data set</td>\n",
       "      <td></td>\n",
       "      <td>We modeled a simultaneous multi-round auction ...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>151 Instances</td>\n",
       "      <td>5 Features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>KDD Cup 1999 Data</td>\n",
       "      <td>Classification</td>\n",
       "      <td>There are three classes/diseases: Bacterial le...</td>\n",
       "      <td>Multivariate, Sequential</td>\n",
       "      <td>5.46K Instances</td>\n",
       "      <td>24 Features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Servo</td>\n",
       "      <td>Regression</td>\n",
       "      <td>This data set contains five text collections i...</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>20.52K Instances</td>\n",
       "      <td>1 Features</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Dataset_Name                               Data_type  \\\n",
       "0                             Iris              Classification, Clustering   \n",
       "1                    Heart Disease                          Classification   \n",
       "2                            Adult                          Classification   \n",
       "3                 Dry Bean Dataset                          Classification   \n",
       "4                         Diabetes  Classification, Regression, Clustering   \n",
       "..                             ...                                     ...   \n",
       "85                Musk (Version 1)                                           \n",
       "86             Haberman's Survival                          Classification   \n",
       "87  Real estate valuation data set                                           \n",
       "88               KDD Cup 1999 Data                          Classification   \n",
       "89                           Servo                              Regression   \n",
       "\n",
       "                                                 Task  \\\n",
       "0   This hourly data set considers 6 main air poll...   \n",
       "1   Accelerometer and transdermal alcohol content ...   \n",
       "2   Contains weekly purchased quantities of 800 ov...   \n",
       "3   Reviews on destinations in 10 categories menti...   \n",
       "4   Bilateral (left, right) joint angle (ankle, kn...   \n",
       "..                                                ...   \n",
       "85  Prediction of the release year of a song from ...   \n",
       "86  This dataset represents ambient data collected...   \n",
       "87  We modeled a simultaneous multi-round auction ...   \n",
       "88  There are three classes/diseases: Bacterial le...   \n",
       "89  This data set contains five text collections i...   \n",
       "\n",
       "               Attribute_type    No_Of_Instances No_of_Attribute  \n",
       "0   Multivariate, Time-Series      399 Instances      4 Features  \n",
       "1                Multivariate     288K Instances     49 Features  \n",
       "2   Multivariate, Time-Series      329 Instances     12 Features  \n",
       "3          Multivariate, Text   24.02K Instances   2.4K Features  \n",
       "4                Multivariate  422.94K Instances      5 Features  \n",
       "..                        ...                ...             ...  \n",
       "85                       Text                                     \n",
       "86  Multivariate, Time-Series      237 Instances      9 Features  \n",
       "87               Multivariate      151 Instances      5 Features  \n",
       "88   Multivariate, Sequential    5.46K Instances     24 Features  \n",
       "89                    Tabular   20.52K Instances      1 Features  \n",
       "\n",
       "[90 rows x 6 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe\n",
    "df8=pd.DataFrame({'Dataset_Name':dsname,'Data_type':dtype,'Task':task,'Attribute_type':att_type,'No_Of_Instances':instances,'No_of_Attribute':no_att})\n",
    "df8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c3a1d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
